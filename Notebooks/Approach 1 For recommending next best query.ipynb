{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How the recommendation  system works for a single user\n",
    "\n",
    "#### The dataset structure\n",
    "| User query  | Context     | user_id |\n",
    "| ----------- | ----------- | --------|\n",
    "| query1      | 0/1/2       |   1     |\n",
    "| query2      | 0/1/2       |   2     |\n",
    "\n",
    "Here the query is simply the user query, context can be of three types: Cause of disease/allergy(0), medication/treatment of disease/allergy(1), symptom of disease/allergy(2). Since a mdeical query can belong to any one of the contexts. \n",
    "\n",
    "#### How the recommendation takes place\n",
    "1. Take user's input query ```q1```\n",
    "2. Convert the query into vector  using tf-idf vectorisation technique\n",
    "3. Try to predict the context of query using text classification methods(random forest, gradient boost) or Bert classification\n",
    "4. Now suggest user the next best query belonging to the same context using text matching algorithms(cosine similarity, neural net)\n",
    "\n",
    "In above method, we can try the steps 2,3 with both simple and advanced methods. Thus we can follow the two approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pg21p\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#For Data preprocessing\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "ls= WordNetLemmatizer()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>disease</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is allergic rhinitis ?</td>\n",
       "      <td>allergic rhintis</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the signs and symptoms of allergic rh...</td>\n",
       "      <td>allergic rhintis</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the complications of allergic rhinitis ?</td>\n",
       "      <td>allergic rhintis</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are the nasal symptoms of allergic rhinit...</td>\n",
       "      <td>allergic rhintis</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the ear, eye and throat symptoms of a...</td>\n",
       "      <td>allergic rhintis</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query           disease  \\\n",
       "0                        What is allergic rhinitis ?  allergic rhintis   \n",
       "1  What are the signs and symptoms of allergic rh...  allergic rhintis   \n",
       "2  What are the complications of allergic rhinitis ?  allergic rhintis   \n",
       "3  What are the nasal symptoms of allergic rhinit...  allergic rhintis   \n",
       "4  What are the ear, eye and throat symptoms of a...  allergic rhintis   \n",
       "\n",
       "   context  \n",
       "0      0.0  \n",
       "1      2.0  \n",
       "2      2.0  \n",
       "3      2.0  \n",
       "4      2.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the dataset\n",
    "df=pd.read_csv('allery-V1.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    48\n",
       "0.0    43\n",
       "2.0    21\n",
       "Name: context, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the total count of contexts\n",
    "df['context'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Taking the disease \"allergic rhintis\" and considering it's all queries refer to user 1 and storing in a new dataset\n",
    "df_new=df[df.disease=='allergic rhintis']\n",
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying basic pre-processing on the user queries\n",
    "sentences=df_new['query']\n",
    "corpus=[]\n",
    "for i in range(0, len(sentences)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', sentences[i]) #keeping only alphabets and removing all other characters \n",
    "    review = review.lower() #converting to lowercase\n",
    "    review = review.split()\n",
    "    \n",
    "    review = [ls.lemmatize(word) for word in review if not word in stopwords.words('english')] #performing lemmatisation\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review) #appending to the array corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting to dataframe\n",
    "corpus=pd.DataFrame(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking context column from loaded dataset\n",
    "corpus['context']=df_new['context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allergic rhinitis</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sign symptom allergic rhinitis</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>complication allergic rhinitis</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nasal symptom allergic rhinitis</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ear eye throat symptom allergic rhinitis</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          0  context\n",
       "0                         allergic rhinitis      0.0\n",
       "1            sign symptom allergic rhinitis      2.0\n",
       "2            complication allergic rhinitis      2.0\n",
       "3           nasal symptom allergic rhinitis      2.0\n",
       "4  ear eye throat symptom allergic rhinitis      2.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#final dataset obtained after preprocessing\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming column'0' to 'query'\n",
    "corpus.columns=['query','context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allergic rhinitis</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sign symptom allergic rhinitis</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>complication allergic rhinitis</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nasal symptom allergic rhinitis</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ear eye throat symptom allergic rhinitis</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      query  context\n",
       "0                         allergic rhinitis      0.0\n",
       "1            sign symptom allergic rhinitis      2.0\n",
       "2            complication allergic rhinitis      2.0\n",
       "3           nasal symptom allergic rhinitis      2.0\n",
       "4  ear eye throat symptom allergic rhinitis      2.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorising the queries\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features = 100) #max length was not more than 100, thus setting 100 features\n",
    "X = cv.fit_transform(corpus['query']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#usinf tf-idf vectorisation\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tf_transformer = TfidfTransformer()\n",
    "X = tf_transformer.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, corpus['context'], test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=2, random_state=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Applying random forest to classify the queries context\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pg21p\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\pg21p\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\pg21p\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.75      0.55         4\n",
      "         1.0       0.60      0.75      0.67         4\n",
      "         2.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.50        12\n",
      "   macro avg       0.34      0.50      0.40        12\n",
      "weighted avg       0.34      0.50      0.40        12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the next code cell,we are following the steps:\n",
    "1. Taking a test query and vectorising it using tf-idf\n",
    "2. Adding extra 0 columns to make it equal to the train dataset shape for prediction\n",
    "3. Once we get the \"test_context\", which is the context value for test query predicted using random forest, we take all the queries from the dataset which match the value of \"test_context\".\n",
    "4. Try cosine similarity to find next best query for the test query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking a test query\n",
    "test_query = \"I have allergic rhintis. what should i do\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting query to vector\n",
    "test_query_arr=cv.fit_transform([test_query]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query_tfidf = tf_transformer.fit_transform(test_query_arr).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying padding, i.e. adding extra '0' columns to match the shape of train dataset\n",
    "columns=[[0]]\n",
    "for i in range(0,94):\n",
    "    test_query_tfidf = np.append(test_query_tfidf, columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the context of test query\n",
    "test_context=clf.predict(test_query_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the query belongs to context [1.]\n"
     ]
    }
   ],
   "source": [
    "print('the query belongs to context',test_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the context is predicted '1', which means this belongs to a medication type query. Also if we look at our original query which was \"I have allergic rhintis. what should i do\", we can observe that next best query recommendation can be of any medication like \"medication/treatment of allergic rhintis\". This tells that our model was able to predict right context for this query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing all queries in an array which have context==test_context\n",
    "query_similarto_test=[]\n",
    "for i in range(0,len(corpus)):\n",
    "    if corpus['context'][i]==test_context:\n",
    "        query_similarto_test.append(corpus['query'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to take up every query from \"query_similarto_test\" array and finding it's cosine similarity with the test query, \n",
    "# the query for which we get the maximum cosine similarity, we will suggest that query to user.\n",
    "# Compute Cosine Similarity\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity=-1\n",
    "max_similarity=-1\n",
    "index=-1\n",
    "next_best_query=\" \"\n",
    "\n",
    "for query in query_similarto_test:\n",
    "    \n",
    "    similarity=cosine_similarity(test_query,corpus['query'][i])\n",
    "    if(similarity>max_sim):\n",
    "        max_sim=similarity\n",
    "        next_best_query=query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next_best_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the libraries\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train dataset into train, validation and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_text, temp_text, train_labels, temp_labels = train_test_split(df_new['query'], df_new['context'], \n",
    "                                                                    random_state=2018, \n",
    "                                                                    test_size=0.2, \n",
    "                                                                    stratify=df_new['context'])\n",
    "\n",
    "\n",
    "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
    "                                                                random_state=2018, \n",
    "                                                                test_size=0.2, \n",
    "                                                                stratify=temp_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# import BERT-base pretrained model\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get length of all the messages in the train set\n",
    "seq_len = [len(i.split()) for i in train_text]\n",
    "\n",
    "pd.Series(seq_len).hist(bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pg21p\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "# tokenize and encode sequences in the training set\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text.tolist(),\n",
    "    max_length = 13, #setting to 13, since this is the one with highest queries\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_text.tolist(),\n",
    "    max_length = 13,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the test set\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_text.tolist(),\n",
    "    max_length = 13,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())\n",
    "\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(val_labels.tolist())\n",
    "\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(test_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "#define a batch size\n",
    "batch_size = 32\n",
    "\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "\n",
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# freeze all the parameters\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "\n",
    "    def __init__(self, bert):\n",
    "        super(BERT_Arch, self).__init__()\n",
    "\n",
    "        self.bert = bert \n",
    "      \n",
    "      # dropout layer\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "      \n",
    "      # relu activation function\n",
    "        self.relu =  nn.ReLU()\n",
    "\n",
    "      # dense layer 1\n",
    "        self.fc1 = nn.Linear(768,512)\n",
    "      \n",
    "      # dense layer 2 (Output layer)\n",
    "        self.fc2 = nn.Linear(512,2)\n",
    "\n",
    "      #softmax activation function\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    #define the forward pass\n",
    "    def forward(self, sent_id, mask):\n",
    "        #pass the inputs to the model  \n",
    "        _, cls_hs = self.bert(sent_id, attention_mask=mask)\n",
    "      \n",
    "        x = self.fc1(cls_hs)\n",
    "\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "      # output layer\n",
    "        x = self.fc2(x)\n",
    "      \n",
    "      # apply softmax activation\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the pre-trained BERT to our define architecture\n",
    "model = BERT_Arch(bert)\n",
    "\n",
    "# push the model to GPU\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
