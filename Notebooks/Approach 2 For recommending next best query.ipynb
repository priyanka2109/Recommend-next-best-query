{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pg21p\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#For Data preprocessing\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "ls= WordNetLemmatizer()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>disease</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is allergic rhinitis ?</td>\n",
       "      <td>allergic rhintis</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the signs and symptoms of allergic rh...</td>\n",
       "      <td>allergic rhintis</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the complications of allergic rhinitis ?</td>\n",
       "      <td>allergic rhintis</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are the nasal symptoms of allergic rhinit...</td>\n",
       "      <td>allergic rhintis</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the ear, eye and throat symptoms of a...</td>\n",
       "      <td>allergic rhintis</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query           disease  \\\n",
       "0                        What is allergic rhinitis ?  allergic rhintis   \n",
       "1  What are the signs and symptoms of allergic rh...  allergic rhintis   \n",
       "2  What are the complications of allergic rhinitis ?  allergic rhintis   \n",
       "3  What are the nasal symptoms of allergic rhinit...  allergic rhintis   \n",
       "4  What are the ear, eye and throat symptoms of a...  allergic rhintis   \n",
       "\n",
       "   context  \n",
       "0      0.0  \n",
       "1      2.0  \n",
       "2      2.0  \n",
       "3      2.0  \n",
       "4      2.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the dataset\n",
    "df=pd.read_csv('allery-V1.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Taking the disease \"allergic rhintis\" and considering it's all queries refer to user 1 and storing in a new dataset\n",
    "df_new=df[df.disease=='allergic rhintis']\n",
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForNextSentencePrediction: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForNextSentencePrediction\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What is allergic rhinitis ?\"\n",
    "next_sentence = \"What are the complications of allergic rhinitis ?\"\n",
    "\n",
    "encoding = tokenizer(prompt, next_sentence, return_tensors='pt')\n",
    "\n",
    "outputs = model(**encoding, labels=torch.LongTensor([1]))\n",
    "logits = outputs.logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12.7992, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. use NSP to predic next most probable query\n",
    "2. this gives us the context of the query as well\n",
    "3. use naive bayes to find context?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://ceur-ws.org/Vol-2774/paper-02.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How the recommendation  system works for a single user\n",
    "\n",
    "#### The dataset structure\n",
    "| User query  | Context     | user_id | next_best_context |\n",
    "| ----------- | ----------- | --------|-------------------|\n",
    "| query1      | 0/1/2       |   1     |     2             |\n",
    "| query2      | 0/1/2       |   2     |     3             |\n",
    "\n",
    "Here the query is simply the user query, context can be of three types: Cause of disease/allergy(0), medication/treatment of disease/allergy(1), symptom of disease/allergy(2). Since a mdeical query can belong to any one of the contexts. \n",
    "\n",
    "#### How the recommendation takes place\n",
    "1. Take user's input query ```q1```\n",
    "2. Convert the query into vector  using tf-idf vectorisation technique\n",
    "3. Try to predict the context of query using text classification methods(random forest, gradient boost) or Bert classification\n",
    "4. Now suggest user the next best query belonging to the same context using text matching algorithms(cosine similarity, neural net)\n",
    "\n",
    "In above method, we can try the steps 2,3 with both simple and advanced methods. Thus we can follow the two approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new approach\n"
     ]
    }
   ],
   "source": [
    "print(\"new approach\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.2'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert-for-tf2\n",
      "  Downloading bert-for-tf2-0.14.9.tar.gz (41 kB)\n",
      "Collecting py-params>=0.9.6\n",
      "  Downloading py-params-0.10.2.tar.gz (7.4 kB)\n",
      "Collecting params-flow>=0.8.0\n",
      "  Downloading params-flow-0.8.2.tar.gz (22 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\pg21p\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from params-flow>=0.8.0->bert-for-tf2) (1.19.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\pg21p\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from params-flow>=0.8.0->bert-for-tf2) (4.31.1)\n",
      "Building wheels for collected packages: bert-for-tf2, py-params, params-flow\n",
      "  Building wheel for bert-for-tf2 (setup.py): started\n",
      "  Building wheel for bert-for-tf2 (setup.py): finished with status 'done'\n",
      "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.9-py3-none-any.whl size=30538 sha256=6bf546e0e86b92d7eddf0f1d04b34a1f161cf50d8353c887a26979dde801bef1\n",
      "  Stored in directory: c:\\users\\pg21p\\appdata\\local\\pip\\cache\\wheels\\47\\b6\\e5\\8c76ec779f54bc5c2f1b57d2200bb9c77616da83873e8acb53\n",
      "  Building wheel for py-params (setup.py): started\n",
      "  Building wheel for py-params (setup.py): finished with status 'done'\n",
      "  Created wheel for py-params: filename=py_params-0.10.2-py3-none-any.whl size=7915 sha256=169f89c7c8d722b13af4e25b11541827f9733663d3af1228bde4db141fc7faba\n",
      "  Stored in directory: c:\\users\\pg21p\\appdata\\local\\pip\\cache\\wheels\\e1\\11\\67\\33cc51bbee127cb8fb2ba549cd29109b2f22da43ddf9969716\n",
      "  Building wheel for params-flow (setup.py): started\n",
      "  Building wheel for params-flow (setup.py): finished with status 'done'\n",
      "  Created wheel for params-flow: filename=params_flow-0.8.2-py3-none-any.whl size=19477 sha256=88c5e4df01f909c68834d26ba22765bf95142fc7f18186723116f1a0f44c8b63\n",
      "  Stored in directory: c:\\users\\pg21p\\appdata\\local\\pip\\cache\\wheels\\0e\\fc\\d2\\a44fff33af0f233d7def6e7de413006d57c10e10ad736fe8f5\n",
      "Successfully built bert-for-tf2 py-params params-flow\n",
      "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
      "Successfully installed bert-for-tf2-0.14.9 params-flow-0.8.2 py-params-0.10.2\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.95-cp37-cp37m-win_amd64.whl (1.2 MB)\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.95\n"
     ]
    }
   ],
   "source": [
    "!pip install bert-for-tf2\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# new approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The dataset structure\n",
    "| User query  | Context     | user_id | next_best_context |\n",
    "| ----------- | ----------- | --------|-------------------|\n",
    "| query1      | 0/1/2       |   1     |     2             |\n",
    "| query2      | 0/1/2       |   2     |     3             |\n",
    "\n",
    "## How it will work\n",
    "1. Train the model with existing dataset\n",
    "2. For a new query, try predicting its next context using the trained model.\n",
    "3. Now when we get a context, we try NSP to find next most probable query of that particular context and display it.\n",
    "4. Now same happens for upcoming query. but we already now have 2 queries into user history now, how to take account for them? may be we can make up a context probability table, and everytime a new query with specific context is suggested, we increase the count(and corresponding probability/log likelihood) of that context and take it into account from next time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "import bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pg21p\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#For Data preprocessing\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "ls= WordNetLemmatizer()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>disease</th>\n",
       "      <th>context</th>\n",
       "      <th>next_best_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is allergic rhinitis ?</td>\n",
       "      <td>allergic rhintis</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the signs and symptoms of allergic rh...</td>\n",
       "      <td>allergic rhintis</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the complications of allergic rhinitis ?</td>\n",
       "      <td>allergic rhintis</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are the nasal symptoms of allergic rhinit...</td>\n",
       "      <td>allergic rhintis</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the ear, eye and throat symptoms of a...</td>\n",
       "      <td>allergic rhintis</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query           disease  \\\n",
       "0                        What is allergic rhinitis ?  allergic rhintis   \n",
       "1  What are the signs and symptoms of allergic rh...  allergic rhintis   \n",
       "2  What are the complications of allergic rhinitis ?  allergic rhintis   \n",
       "3  What are the nasal symptoms of allergic rhinit...  allergic rhintis   \n",
       "4  What are the ear, eye and throat symptoms of a...  allergic rhintis   \n",
       "\n",
       "   context  next_best_context  \n",
       "0      0.0                2.0  \n",
       "1      2.0                1.0  \n",
       "2      2.0                0.0  \n",
       "3      2.0                2.0  \n",
       "4      2.0                2.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the dataset\n",
    "df=pd.read_csv('allergy-V1.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Taking the disease \"allergic rhintis\" and considering it's all queries refer to user 1 and storing in a new dataset\n",
    "df_new=df[df.disease=='allergic rhintis']\n",
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>disease</th>\n",
       "      <th>context</th>\n",
       "      <th>next_best_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is allergic rhinitis ?</td>\n",
       "      <td>allergic rhintis</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the signs and symptoms of allergic rh...</td>\n",
       "      <td>allergic rhintis</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the complications of allergic rhinitis ?</td>\n",
       "      <td>allergic rhintis</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are the nasal symptoms of allergic rhinit...</td>\n",
       "      <td>allergic rhintis</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the ear, eye and throat symptoms of a...</td>\n",
       "      <td>allergic rhintis</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Which medications in the drug class Nasal cort...</td>\n",
       "      <td>allergic rhintis</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Which medications in the drug class Antihistam...</td>\n",
       "      <td>allergic rhintis</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Which medications in the drug class Mast Cell ...</td>\n",
       "      <td>allergic rhintis</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Which medications in the drug class Intranasal...</td>\n",
       "      <td>allergic rhintis</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Which medications in the drug class Allergen I...</td>\n",
       "      <td>allergic rhintis</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 query           disease  \\\n",
       "0                          What is allergic rhinitis ?  allergic rhintis   \n",
       "1    What are the signs and symptoms of allergic rh...  allergic rhintis   \n",
       "2    What are the complications of allergic rhinitis ?  allergic rhintis   \n",
       "3    What are the nasal symptoms of allergic rhinit...  allergic rhintis   \n",
       "4    What are the ear, eye and throat symptoms of a...  allergic rhintis   \n",
       "..                                                 ...               ...   \n",
       "107  Which medications in the drug class Nasal cort...  allergic rhintis   \n",
       "108  Which medications in the drug class Antihistam...  allergic rhintis   \n",
       "109  Which medications in the drug class Mast Cell ...  allergic rhintis   \n",
       "110  Which medications in the drug class Intranasal...  allergic rhintis   \n",
       "111  Which medications in the drug class Allergen I...  allergic rhintis   \n",
       "\n",
       "     context  next_best_context  \n",
       "0        0.0                2.0  \n",
       "1        2.0                1.0  \n",
       "2        2.0                0.0  \n",
       "3        2.0                2.0  \n",
       "4        2.0                2.0  \n",
       "..       ...                ...  \n",
       "107      1.0                2.0  \n",
       "108      1.0                2.0  \n",
       "109      1.0                0.0  \n",
       "110      1.0                2.0  \n",
       "111      1.0                0.0  \n",
       "\n",
       "[112 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'run_classifier' from 'bert' (C:\\Users\\pg21p\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\bert\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-1ccb11d8dffa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbert\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mbert\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrun_classifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbert\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptimization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbert\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtokenization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'run_classifier' from 'bert' (C:\\Users\\pg21p\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\bert\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pg21p\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\pg21p\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3343: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      2.0\n",
       "1      1.0\n",
       "2      3.0\n",
       "3      2.0\n",
       "4      2.0\n",
       "      ... \n",
       "107    2.0\n",
       "108    2.0\n",
       "109    3.0\n",
       "110    2.0\n",
       "111    3.0\n",
       "Name: next_best_context, Length: 112, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(0,112):\n",
    "    if(df_new['next_best_context'][i]==0):\n",
    "        df_new['next_best_context'][i]=3\n",
    "df_new['next_best_context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val =  train_test_split(df_new, test_size = 0.2, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_COLUMN = 'query'\n",
    "LABEL_COLUMN = 'next_best_context'\n",
    "label_list = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'bert' has no attribute 'run_classifier'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-c532599a1518>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m                                                                    \u001b[0mtext_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mDATA_COLUMN\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                                                    \u001b[0mtext_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m                                                                    label = x[LABEL_COLUMN]), axis = 1)\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m val_InputExamples = val.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[0;32m   6876\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6877\u001b[0m         )\n\u001b[1;32m-> 6878\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6880\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"DataFrame\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m                 result = libreduction.compute_reduction(\n\u001b[1;32m--> 296\u001b[1;33m                     \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdummy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdummy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 )\n\u001b[0;32m    298\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.compute_reduction\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.Reducer.get_result\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-c532599a1518>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None,\n\u001b[0m\u001b[0;32m      2\u001b[0m                                                                    \u001b[0mtext_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mDATA_COLUMN\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                                                    \u001b[0mtext_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                                                    label = x[LABEL_COLUMN]), axis = 1)\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'bert' has no attribute 'run_classifier'"
     ]
    }
   ],
   "source": [
    "train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None,\n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "val_InputExamples = val.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_queries=df_new['query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_context=df_new['next_best_context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "BertTokenizer = bert.bert_tokenization.FullTokenizer #making tokeniser object\n",
    "#bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
    "                            #trainable=False) #downloading the embedding layer of bert model\n",
    "vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy() #saving as vocablary\n",
    "to_lower_case = bert_layer.resolved_object.do_lower_case.numpy() \n",
    "tokenizer = BertTokenizer(vocabulary_file, to_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['don', \"'\", 't', 'be', 'so', 'judgment', '##al']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"don't be so judgmental\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2123, 2102, 2022, 2061, 8689, 2389]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\"dont be so judgmental\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_queries(medical_query):\n",
    "    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(medical_query))\n",
    "\n",
    "tokenized_queries = [tokenize_queries(query) for query in df_new['query']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_with_len = [[med_query, med_context[i], len(med_query)]\n",
    "                 for i, med_query in enumerate(tokenized_queries)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[2054, 2003, 27395, 1054, 20535, 7315, 1029], 2.0, 7],\n",
       " [[2054, 2024, 1996, 5751, 1998, 8030, 1997, 27395, 1054, 20535, 7315, 1029],\n",
       "  1.0,\n",
       "  12],\n",
       " [[2054, 2024, 1996, 12763, 1997, 27395, 1054, 20535, 7315, 1029], 3.0, 10],\n",
       " [[2054, 2024, 1996, 19077, 8030, 1997, 27395, 1054, 20535, 7315, 1029],\n",
       "  2.0,\n",
       "  11],\n",
       " [[2054,\n",
       "   2024,\n",
       "   1996,\n",
       "   4540,\n",
       "   1010,\n",
       "   3239,\n",
       "   1998,\n",
       "   3759,\n",
       "   8030,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  2.0,\n",
       "  15],\n",
       " [[2029,\n",
       "   6845,\n",
       "   5852,\n",
       "   2024,\n",
       "   2109,\n",
       "   1999,\n",
       "   1996,\n",
       "   11616,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  2.0,\n",
       "  14],\n",
       " [[2129,\n",
       "   2024,\n",
       "   12126,\n",
       "   2913,\n",
       "   2109,\n",
       "   1999,\n",
       "   1996,\n",
       "   11616,\n",
       "   1998,\n",
       "   9312,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  3.0,\n",
       "  16],\n",
       " [[2054, 2024, 1996, 2350, 3949, 9942, 2005, 27395, 1054, 20535, 7315, 1029],\n",
       "  1.0,\n",
       "  12],\n",
       " [[2054, 2003, 1996, 3171, 10859, 1997, 27395, 1054, 20535, 7315, 1029],\n",
       "  1.0,\n",
       "  11],\n",
       " [[2054,\n",
       "   2003,\n",
       "   1996,\n",
       "   4130,\n",
       "   7361,\n",
       "   10536,\n",
       "   20763,\n",
       "   6483,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  2.0,\n",
       "  14],\n",
       " [[2054,\n",
       "   2003,\n",
       "   1996,\n",
       "   2535,\n",
       "   1997,\n",
       "   10047,\n",
       "   23041,\n",
       "   8649,\n",
       "   4135,\n",
       "   8569,\n",
       "   4115,\n",
       "   1041,\n",
       "   1006,\n",
       "   1045,\n",
       "   3351,\n",
       "   1007,\n",
       "   1999,\n",
       "   1996,\n",
       "   26835,\n",
       "   19009,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  3.0,\n",
       "  26],\n",
       " [[2029,\n",
       "   2865,\n",
       "   6591,\n",
       "   2024,\n",
       "   3202,\n",
       "   2207,\n",
       "   1999,\n",
       "   1996,\n",
       "   26835,\n",
       "   19009,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  1.0,\n",
       "  16],\n",
       " [[2054, 2024, 22575, 3896, 1997, 27395, 1054, 20535, 7315, 1029], 2.0, 10],\n",
       " [[2054,\n",
       "   2003,\n",
       "   1996,\n",
       "   20272,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1999,\n",
       "   1996,\n",
       "   2149,\n",
       "   1029],\n",
       "  1.0,\n",
       "  13],\n",
       " [[2054, 2003, 1996, 3795, 20272, 1997, 27395, 1054, 20535, 7315, 1029],\n",
       "  1.0,\n",
       "  11],\n",
       " [[2054,\n",
       "   2003,\n",
       "   1996,\n",
       "   13356,\n",
       "   1998,\n",
       "   22822,\n",
       "   17062,\n",
       "   6447,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  2.0,\n",
       "  14],\n",
       " [[2054,\n",
       "   2024,\n",
       "   5762,\n",
       "   3653,\n",
       "   4305,\n",
       "   2571,\n",
       "   22014,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  1.0,\n",
       "  13],\n",
       " [[2129,\n",
       "   2515,\n",
       "   1996,\n",
       "   20272,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   8137,\n",
       "   2011,\n",
       "   3348,\n",
       "   1029],\n",
       "  3.0,\n",
       "  13],\n",
       " [[2129,\n",
       "   2515,\n",
       "   1996,\n",
       "   20272,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   8137,\n",
       "   2011,\n",
       "   2287,\n",
       "   1029],\n",
       "  3.0,\n",
       "  13],\n",
       " [[2054,\n",
       "   2003,\n",
       "   1996,\n",
       "   3579,\n",
       "   1997,\n",
       "   2381,\n",
       "   2005,\n",
       "   6878,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  3.0,\n",
       "  13],\n",
       " [[2054, 2024, 8030, 1997, 27395, 1054, 20535, 7315, 1029], 1.0, 9],\n",
       " [[2012,\n",
       "   2054,\n",
       "   2287,\n",
       "   2003,\n",
       "   1996,\n",
       "   14447,\n",
       "   1997,\n",
       "   8030,\n",
       "   2005,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   2087,\n",
       "   2691,\n",
       "   1029],\n",
       "  2.0,\n",
       "  16],\n",
       " [[2054,\n",
       "   2003,\n",
       "   1996,\n",
       "   7784,\n",
       "   1997,\n",
       "   1037,\n",
       "   2051,\n",
       "   5418,\n",
       "   2000,\n",
       "   8030,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  3.0,\n",
       "  16],\n",
       " [[2129, 2003, 27395, 1054, 20535, 7315, 6219, 1029], 3.0, 8],\n",
       " [[2054, 2003, 1996, 7784, 1997, 20176, 1999, 27395, 1054, 20535, 7315, 1029],\n",
       "  1.0,\n",
       "  12],\n",
       " [[2054, 2024, 2825, 9495, 5876, 2005, 27395, 1054, 20535, 7315, 1029],\n",
       "  1.0,\n",
       "  11],\n",
       " [[2054,\n",
       "   2024,\n",
       "   20868,\n",
       "   25279,\n",
       "   2102,\n",
       "   27099,\n",
       "   3378,\n",
       "   2007,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  1.0,\n",
       "  13],\n",
       " [[2029,\n",
       "   14638,\n",
       "   2035,\n",
       "   2121,\n",
       "   21230,\n",
       "   2089,\n",
       "   3426,\n",
       "   11888,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  3.0,\n",
       "  13],\n",
       " [[2054,\n",
       "   2003,\n",
       "   5393,\n",
       "   2011,\n",
       "   3433,\n",
       "   2000,\n",
       "   13441,\n",
       "   2005,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  2.0,\n",
       "  13],\n",
       " [[2029, 10234, 2594, 3785, 2024, 3378, 2007, 27395, 1054, 20535, 7315, 1029],\n",
       "  1.0,\n",
       "  12],\n",
       " [[2054, 2024, 12763, 1997, 27395, 1054, 20535, 7315, 1029], 3.0, 9],\n",
       " [[2339,\n",
       "   2003,\n",
       "   1996,\n",
       "   3891,\n",
       "   2005,\n",
       "   4975,\n",
       "   27885,\n",
       "   3367,\n",
       "   6820,\n",
       "   15277,\n",
       "   3637,\n",
       "   9706,\n",
       "   22084,\n",
       "   1006,\n",
       "   9808,\n",
       "   2050,\n",
       "   1007,\n",
       "   3445,\n",
       "   1999,\n",
       "   5022,\n",
       "   2007,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  3.0,\n",
       "  26],\n",
       " [[2054,\n",
       "   2003,\n",
       "   1996,\n",
       "   2535,\n",
       "   1997,\n",
       "   9530,\n",
       "   9006,\n",
       "   25451,\n",
       "   2102,\n",
       "   2966,\n",
       "   3785,\n",
       "   1999,\n",
       "   1996,\n",
       "   11616,\n",
       "   1998,\n",
       "   3949,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  3.0,\n",
       "  21],\n",
       " [[2029,\n",
       "   3785,\n",
       "   3623,\n",
       "   1996,\n",
       "   3891,\n",
       "   2005,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1999,\n",
       "   2336,\n",
       "   1029],\n",
       "  1.0,\n",
       "  13],\n",
       " [[2054,\n",
       "   2003,\n",
       "   1996,\n",
       "   2535,\n",
       "   1997,\n",
       "   2155,\n",
       "   2381,\n",
       "   1999,\n",
       "   1996,\n",
       "   11616,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  2.0,\n",
       "  16],\n",
       " [[2029,\n",
       "   4483,\n",
       "   7524,\n",
       "   2015,\n",
       "   2323,\n",
       "   2022,\n",
       "   1996,\n",
       "   3579,\n",
       "   1997,\n",
       "   2381,\n",
       "   1999,\n",
       "   6878,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  1.0,\n",
       "  17],\n",
       " [[2054,\n",
       "   2003,\n",
       "   1996,\n",
       "   3466,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   2006,\n",
       "   3737,\n",
       "   1997,\n",
       "   2166,\n",
       "   1029],\n",
       "  2.0,\n",
       "  14],\n",
       " [[2054,\n",
       "   2003,\n",
       "   1996,\n",
       "   3579,\n",
       "   1997,\n",
       "   1996,\n",
       "   3558,\n",
       "   11360,\n",
       "   2005,\n",
       "   6878,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  1.0,\n",
       "  15],\n",
       " [[2054, 2024, 1996, 13268, 2838, 8281, 1997, 27395, 1054, 20535, 7315, 1029],\n",
       "  1.0,\n",
       "  12],\n",
       " [[2129, 2003, 1996, 19077, 11360, 1997, 27395, 1054, 20535, 7315, 4146, 1029],\n",
       "  1.0,\n",
       "  12],\n",
       " [[2029, 19077, 11360, 9556, 6592, 27395, 1054, 20535, 7315, 1029], 3.0, 10],\n",
       " [[2054,\n",
       "   2323,\n",
       "   2022,\n",
       "   2443,\n",
       "   1999,\n",
       "   1996,\n",
       "   19077,\n",
       "   11360,\n",
       "   1999,\n",
       "   5022,\n",
       "   2007,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  3.0,\n",
       "  16],\n",
       " [[2054,\n",
       "   2003,\n",
       "   1996,\n",
       "   2535,\n",
       "   1997,\n",
       "   27178,\n",
       "   2891,\n",
       "   3597,\n",
       "   7685,\n",
       "   1999,\n",
       "   1996,\n",
       "   2147,\n",
       "   6279,\n",
       "   1997,\n",
       "   6878,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  1.0,\n",
       "  20],\n",
       " [[2054,\n",
       "   2024,\n",
       "   1051,\n",
       "   15431,\n",
       "   11360,\n",
       "   9556,\n",
       "   8281,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  1.0,\n",
       "  13],\n",
       " [[2029,\n",
       "   3558,\n",
       "   9556,\n",
       "   1999,\n",
       "   1996,\n",
       "   3759,\n",
       "   2024,\n",
       "   8281,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  1.0,\n",
       "  14],\n",
       " [[2054,\n",
       "   2003,\n",
       "   1996,\n",
       "   3579,\n",
       "   1997,\n",
       "   1996,\n",
       "   3300,\n",
       "   11360,\n",
       "   1999,\n",
       "   6878,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  3.0,\n",
       "  15],\n",
       " [[2054,\n",
       "   2003,\n",
       "   1996,\n",
       "   3579,\n",
       "   1999,\n",
       "   1996,\n",
       "   16464,\n",
       "   11360,\n",
       "   1999,\n",
       "   6878,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  3.0,\n",
       "  15],\n",
       " [[2054,\n",
       "   2003,\n",
       "   1996,\n",
       "   3579,\n",
       "   1997,\n",
       "   1996,\n",
       "   4315,\n",
       "   18900,\n",
       "   12898,\n",
       "   12863,\n",
       "   11360,\n",
       "   1999,\n",
       "   6878,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  3.0,\n",
       "  18],\n",
       " [[2029,\n",
       "   22575,\n",
       "   7870,\n",
       "   2323,\n",
       "   2022,\n",
       "   2641,\n",
       "   1999,\n",
       "   1996,\n",
       "   3558,\n",
       "   11360,\n",
       "   2005,\n",
       "   6878,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  1.0,\n",
       "  17],\n",
       " [[2054, 2024, 1996, 5320, 1997, 27395, 1054, 20535, 7315, 1029], 1.0, 10],\n",
       " [[2054, 2003, 1996, 3426, 1997, 12348, 27395, 1054, 20535, 7315, 1029],\n",
       "  1.0,\n",
       "  11],\n",
       " [[2054,\n",
       "   2024,\n",
       "   2691,\n",
       "   3392,\n",
       "   22482,\n",
       "   2015,\n",
       "   2008,\n",
       "   3426,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  2.0,\n",
       "  13],\n",
       " [[2054,\n",
       "   2024,\n",
       "   2691,\n",
       "   5568,\n",
       "   22482,\n",
       "   2015,\n",
       "   2008,\n",
       "   3426,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  2.0,\n",
       "  13],\n",
       " [[2054,\n",
       "   2024,\n",
       "   2070,\n",
       "   2691,\n",
       "   17901,\n",
       "   22482,\n",
       "   2015,\n",
       "   2008,\n",
       "   3426,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  2.0,\n",
       "  14],\n",
       " [[2129,\n",
       "   2079,\n",
       "   12483,\n",
       "   3785,\n",
       "   7461,\n",
       "   1996,\n",
       "   4487,\n",
       "   17668,\n",
       "   10992,\n",
       "   1997,\n",
       "   18282,\n",
       "   2008,\n",
       "   3426,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  1.0,\n",
       "  18],\n",
       " [[2054, 2003, 1996, 3426, 1997, 14638, 27395, 1054, 20535, 7315, 1029],\n",
       "  1.0,\n",
       "  11],\n",
       " [[2029,\n",
       "   2160,\n",
       "   6497,\n",
       "   10210,\n",
       "   2063,\n",
       "   2427,\n",
       "   4141,\n",
       "   3426,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  1.0,\n",
       "  13],\n",
       " [[2029,\n",
       "   18551,\n",
       "   2024,\n",
       "   2087,\n",
       "   3497,\n",
       "   2000,\n",
       "   3426,\n",
       "   14638,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  1.0,\n",
       "  13],\n",
       " [[2029,\n",
       "   14211,\n",
       "   2003,\n",
       "   1037,\n",
       "   2691,\n",
       "   3426,\n",
       "   1997,\n",
       "   14638,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  2.0,\n",
       "  13],\n",
       " [[2029, 20739, 1999, 14081, 3370, 2064, 3426, 27395, 1054, 20535, 7315, 1029],\n",
       "  2.0,\n",
       "  12],\n",
       " [[2054, 5320, 24590, 27395, 1054, 20535, 7315, 1029], 2.0, 8],\n",
       " [[2054, 2003, 16928, 27395, 1054, 20535, 7315, 1029], 2.0, 8],\n",
       " [[2029,\n",
       "   3785,\n",
       "   2323,\n",
       "   2022,\n",
       "   2443,\n",
       "   1999,\n",
       "   1996,\n",
       "   11658,\n",
       "   22939,\n",
       "   26745,\n",
       "   8583,\n",
       "   2005,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  2.0,\n",
       "  17],\n",
       " [[2054,\n",
       "   2024,\n",
       "   1996,\n",
       "   11658,\n",
       "   22939,\n",
       "   26745,\n",
       "   8583,\n",
       "   2005,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  3.0,\n",
       "  13],\n",
       " [[2054,\n",
       "   2003,\n",
       "   1996,\n",
       "   2535,\n",
       "   1997,\n",
       "   2035,\n",
       "   24395,\n",
       "   5604,\n",
       "   1999,\n",
       "   1996,\n",
       "   11616,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  3.0,\n",
       "  17],\n",
       " [[2129,\n",
       "   2024,\n",
       "   2035,\n",
       "   24395,\n",
       "   3096,\n",
       "   5852,\n",
       "   2109,\n",
       "   2000,\n",
       "   22939,\n",
       "   26745,\n",
       "   3366,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  3.0,\n",
       "  16],\n",
       " [[2129,\n",
       "   2003,\n",
       "   2019,\n",
       "   2035,\n",
       "   24395,\n",
       "   3096,\n",
       "   3231,\n",
       "   2864,\n",
       "   1999,\n",
       "   1996,\n",
       "   11616,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  3.0,\n",
       "  17],\n",
       " [[2129,\n",
       "   2024,\n",
       "   1999,\n",
       "   25714,\n",
       "   2035,\n",
       "   24395,\n",
       "   5852,\n",
       "   2109,\n",
       "   2000,\n",
       "   22939,\n",
       "   26745,\n",
       "   3366,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  3.0,\n",
       "  17],\n",
       " [[2054,\n",
       "   2003,\n",
       "   1996,\n",
       "   3978,\n",
       "   2005,\n",
       "   17739,\n",
       "   2035,\n",
       "   2121,\n",
       "   21230,\n",
       "   2000,\n",
       "   3231,\n",
       "   2005,\n",
       "   1999,\n",
       "   1996,\n",
       "   11616,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  3.0,\n",
       "  21],\n",
       " [[2054,\n",
       "   2003,\n",
       "   1996,\n",
       "   2535,\n",
       "   1997,\n",
       "   10047,\n",
       "   23041,\n",
       "   8649,\n",
       "   4135,\n",
       "   8569,\n",
       "   4115,\n",
       "   1041,\n",
       "   1006,\n",
       "   1045,\n",
       "   3351,\n",
       "   1007,\n",
       "   10903,\n",
       "   1999,\n",
       "   1996,\n",
       "   11616,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  3.0,\n",
       "  26],\n",
       " [[2054,\n",
       "   2003,\n",
       "   1996,\n",
       "   2535,\n",
       "   1997,\n",
       "   2668,\n",
       "   1041,\n",
       "   20049,\n",
       "   3630,\n",
       "   21850,\n",
       "   2140,\n",
       "   4175,\n",
       "   1999,\n",
       "   1996,\n",
       "   11616,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  2.0,\n",
       "  21],\n",
       " [[2054,\n",
       "   2003,\n",
       "   1996,\n",
       "   2535,\n",
       "   1997,\n",
       "   2557,\n",
       "   12565,\n",
       "   1999,\n",
       "   1996,\n",
       "   11616,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  2.0,\n",
       "  16],\n",
       " [[2054,\n",
       "   2003,\n",
       "   1996,\n",
       "   2535,\n",
       "   1997,\n",
       "   14931,\n",
       "   13722,\n",
       "   1999,\n",
       "   1996,\n",
       "   11616,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  2.0,\n",
       "  16],\n",
       " [[2054,\n",
       "   2003,\n",
       "   1996,\n",
       "   2535,\n",
       "   1997,\n",
       "   27011,\n",
       "   1999,\n",
       "   1996,\n",
       "   11616,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  2.0,\n",
       "  15],\n",
       " [[2054,\n",
       "   2003,\n",
       "   1996,\n",
       "   2535,\n",
       "   1997,\n",
       "   19077,\n",
       "   22330,\n",
       "   23479,\n",
       "   1999,\n",
       "   1996,\n",
       "   11616,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  3.0,\n",
       "  17],\n",
       " [[2054,\n",
       "   2003,\n",
       "   1996,\n",
       "   2535,\n",
       "   1997,\n",
       "   3356,\n",
       "   2250,\n",
       "   4576,\n",
       "   2203,\n",
       "   2891,\n",
       "   3597,\n",
       "   7685,\n",
       "   1006,\n",
       "   24091,\n",
       "   28221,\n",
       "   16656,\n",
       "   9363,\n",
       "   7685,\n",
       "   1007,\n",
       "   1999,\n",
       "   1996,\n",
       "   11616,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  3.0,\n",
       "  28],\n",
       " [[2054,\n",
       "   2003,\n",
       "   1996,\n",
       "   2535,\n",
       "   1997,\n",
       "   19077,\n",
       "   4013,\n",
       "   19152,\n",
       "   1006,\n",
       "   2035,\n",
       "   2121,\n",
       "   6914,\n",
       "   4119,\n",
       "   1007,\n",
       "   5604,\n",
       "   1999,\n",
       "   1996,\n",
       "   11616,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  3.0,\n",
       "  24],\n",
       " [[2054, 2024, 1996, 3949, 7047, 2005, 27395, 1054, 20535, 7315, 1029],\n",
       "  3.0,\n",
       "  11],\n",
       " [[2129,\n",
       "   1998,\n",
       "   2043,\n",
       "   2003,\n",
       "   4483,\n",
       "   2491,\n",
       "   1998,\n",
       "   2035,\n",
       "   2121,\n",
       "   6914,\n",
       "   24685,\n",
       "   2109,\n",
       "   1999,\n",
       "   1996,\n",
       "   3949,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  1.0,\n",
       "  21],\n",
       " [[2054,\n",
       "   2024,\n",
       "   1996,\n",
       "   4483,\n",
       "   2491,\n",
       "   5761,\n",
       "   2005,\n",
       "   7254,\n",
       "   2035,\n",
       "   2121,\n",
       "   21230,\n",
       "   2008,\n",
       "   3426,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  2.0,\n",
       "  18],\n",
       " [[2054,\n",
       "   2024,\n",
       "   1996,\n",
       "   4483,\n",
       "   2491,\n",
       "   5761,\n",
       "   2005,\n",
       "   7169,\n",
       "   2035,\n",
       "   2121,\n",
       "   21230,\n",
       "   2008,\n",
       "   3426,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  1.0,\n",
       "  18],\n",
       " [[2054,\n",
       "   2024,\n",
       "   1996,\n",
       "   4483,\n",
       "   2491,\n",
       "   5761,\n",
       "   2005,\n",
       "   7169,\n",
       "   18282,\n",
       "   2008,\n",
       "   3426,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  2.0,\n",
       "  16],\n",
       " [[2054,\n",
       "   2024,\n",
       "   1996,\n",
       "   7169,\n",
       "   4483,\n",
       "   2491,\n",
       "   5761,\n",
       "   2005,\n",
       "   4176,\n",
       "   2008,\n",
       "   3426,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  1.0,\n",
       "  16],\n",
       " [[2054,\n",
       "   2003,\n",
       "   1996,\n",
       "   2190,\n",
       "   4483,\n",
       "   2491,\n",
       "   5468,\n",
       "   2005,\n",
       "   16928,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  2.0,\n",
       "  14],\n",
       " [[2054,\n",
       "   2024,\n",
       "   2825,\n",
       "   2512,\n",
       "   13102,\n",
       "   8586,\n",
       "   18513,\n",
       "   27099,\n",
       "   2005,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  1.0,\n",
       "  14],\n",
       " [[2054,\n",
       "   2003,\n",
       "   1996,\n",
       "   2535,\n",
       "   1997,\n",
       "   6887,\n",
       "   27292,\n",
       "   22684,\n",
       "   12399,\n",
       "   9331,\n",
       "   3111,\n",
       "   1999,\n",
       "   1996,\n",
       "   3949,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  2.0,\n",
       "  20],\n",
       " [[2054,\n",
       "   2003,\n",
       "   1996,\n",
       "   2535,\n",
       "   1997,\n",
       "   10047,\n",
       "   23041,\n",
       "   14573,\n",
       "   6906,\n",
       "   7685,\n",
       "   1999,\n",
       "   1996,\n",
       "   3949,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  2.0,\n",
       "  19],\n",
       " [[2054,\n",
       "   2003,\n",
       "   1996,\n",
       "   2535,\n",
       "   1997,\n",
       "   4942,\n",
       "   2989,\n",
       "   8787,\n",
       "   10047,\n",
       "   23041,\n",
       "   14573,\n",
       "   6906,\n",
       "   7685,\n",
       "   1006,\n",
       "   18036,\n",
       "   1007,\n",
       "   1999,\n",
       "   1996,\n",
       "   3949,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  3.0,\n",
       "  25],\n",
       " [[2029,\n",
       "   4942,\n",
       "   2989,\n",
       "   8787,\n",
       "   1006,\n",
       "   22889,\n",
       "   1007,\n",
       "   13855,\n",
       "   2038,\n",
       "   2042,\n",
       "   4844,\n",
       "   2011,\n",
       "   1996,\n",
       "   17473,\n",
       "   2005,\n",
       "   1996,\n",
       "   3949,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   3303,\n",
       "   2011,\n",
       "   5568,\n",
       "   22482,\n",
       "   2015,\n",
       "   1029],\n",
       "  3.0,\n",
       "  28],\n",
       " [[2129,\n",
       "   2323,\n",
       "   1996,\n",
       "   8700,\n",
       "   11215,\n",
       "   22889,\n",
       "   13855,\n",
       "   2022,\n",
       "   8564,\n",
       "   2005,\n",
       "   1996,\n",
       "   3949,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  3.0,\n",
       "  18],\n",
       " [[2054,\n",
       "   2003,\n",
       "   1996,\n",
       "   2535,\n",
       "   1997,\n",
       "   24665,\n",
       "   14083,\n",
       "   5937,\n",
       "   1999,\n",
       "   1996,\n",
       "   3949,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  3.0,\n",
       "  17],\n",
       " [[2054,\n",
       "   2003,\n",
       "   1996,\n",
       "   2535,\n",
       "   1997,\n",
       "   17768,\n",
       "   9148,\n",
       "   23125,\n",
       "   1999,\n",
       "   1996,\n",
       "   3949,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  3.0,\n",
       "  17],\n",
       " [[2054,\n",
       "   2003,\n",
       "   1996,\n",
       "   2535,\n",
       "   1997,\n",
       "   1051,\n",
       "   2850,\n",
       "   6593,\n",
       "   2527,\n",
       "   1999,\n",
       "   1996,\n",
       "   3949,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  3.0,\n",
       "  18],\n",
       " [[2129,\n",
       "   2003,\n",
       "   1051,\n",
       "   2850,\n",
       "   6593,\n",
       "   2527,\n",
       "   8564,\n",
       "   2005,\n",
       "   1996,\n",
       "   3949,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  2.0,\n",
       "  16],\n",
       " [[2054,\n",
       "   2003,\n",
       "   1996,\n",
       "   21150,\n",
       "   1997,\n",
       "   1051,\n",
       "   2850,\n",
       "   6593,\n",
       "   2527,\n",
       "   1999,\n",
       "   1996,\n",
       "   3949,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  2.0,\n",
       "  18],\n",
       " [[2054,\n",
       "   2024,\n",
       "   1996,\n",
       "   12546,\n",
       "   1997,\n",
       "   4942,\n",
       "   2989,\n",
       "   8787,\n",
       "   10047,\n",
       "   23041,\n",
       "   14573,\n",
       "   6906,\n",
       "   7685,\n",
       "   1006,\n",
       "   18036,\n",
       "   1007,\n",
       "   1999,\n",
       "   1996,\n",
       "   3949,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  2.0,\n",
       "  25],\n",
       " [[2043, 2003, 11707, 2729, 2005, 27395, 1054, 20535, 7315, 5393, 1029],\n",
       "  2.0,\n",
       "  11],\n",
       " [[2054,\n",
       "   2003,\n",
       "   1996,\n",
       "   2535,\n",
       "   1997,\n",
       "   10722,\n",
       "   27366,\n",
       "   7361,\n",
       "   8523,\n",
       "   3723,\n",
       "   1999,\n",
       "   1996,\n",
       "   3949,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  2.0,\n",
       "  19],\n",
       " [[2043,\n",
       "   2323,\n",
       "   8325,\n",
       "   16053,\n",
       "   2022,\n",
       "   2641,\n",
       "   2005,\n",
       "   1996,\n",
       "   3949,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  2.0,\n",
       "  15],\n",
       " [[2054,\n",
       "   2024,\n",
       "   1996,\n",
       "   4101,\n",
       "   4708,\n",
       "   2486,\n",
       "   2006,\n",
       "   3218,\n",
       "   11709,\n",
       "   1006,\n",
       "   1046,\n",
       "   24475,\n",
       "   9397,\n",
       "   1007,\n",
       "   3949,\n",
       "   11594,\n",
       "   2005,\n",
       "   12348,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1006,\n",
       "   18906,\n",
       "   1007,\n",
       "   1999,\n",
       "   25947,\n",
       "   1998,\n",
       "   6001,\n",
       "   1029],\n",
       "  2.0,\n",
       "  30],\n",
       " [[2054,\n",
       "   3145,\n",
       "   11433,\n",
       "   2024,\n",
       "   2443,\n",
       "   1999,\n",
       "   1996,\n",
       "   9779,\n",
       "   11631,\n",
       "   1011,\n",
       "   24978,\n",
       "   2546,\n",
       "   3949,\n",
       "   11594,\n",
       "   2005,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  2.0,\n",
       "  20],\n",
       " [[2029,\n",
       "   20992,\n",
       "   2024,\n",
       "   2109,\n",
       "   1999,\n",
       "   1996,\n",
       "   3949,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  2.0,\n",
       "  13],\n",
       " [[2029,\n",
       "   20992,\n",
       "   1999,\n",
       "   1996,\n",
       "   4319,\n",
       "   2465,\n",
       "   2117,\n",
       "   1011,\n",
       "   4245,\n",
       "   3424,\n",
       "   24158,\n",
       "   15464,\n",
       "   10586,\n",
       "   2024,\n",
       "   2109,\n",
       "   1999,\n",
       "   1996,\n",
       "   3949,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  2.0,\n",
       "  24],\n",
       " [[2029,\n",
       "   20992,\n",
       "   1999,\n",
       "   1996,\n",
       "   4319,\n",
       "   2465,\n",
       "   3393,\n",
       "   6968,\n",
       "   4140,\n",
       "   23144,\n",
       "   2063,\n",
       "   10769,\n",
       "   17379,\n",
       "   2015,\n",
       "   2024,\n",
       "   2109,\n",
       "   1999,\n",
       "   1996,\n",
       "   3949,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  3.0,\n",
       "  25],\n",
       " [[2029,\n",
       "   20992,\n",
       "   1999,\n",
       "   1996,\n",
       "   4319,\n",
       "   2465,\n",
       "   2034,\n",
       "   1011,\n",
       "   4245,\n",
       "   3424,\n",
       "   24158,\n",
       "   15464,\n",
       "   10586,\n",
       "   2024,\n",
       "   2109,\n",
       "   1999,\n",
       "   1996,\n",
       "   3949,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  3.0,\n",
       "  24],\n",
       " [[2029,\n",
       "   20992,\n",
       "   1999,\n",
       "   1996,\n",
       "   4319,\n",
       "   2465,\n",
       "   21933,\n",
       "   15465,\n",
       "   12693,\n",
       "   3215,\n",
       "   2024,\n",
       "   2109,\n",
       "   1999,\n",
       "   1996,\n",
       "   3949,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  3.0,\n",
       "  21],\n",
       " [[2029,\n",
       "   20992,\n",
       "   1999,\n",
       "   1996,\n",
       "   4319,\n",
       "   2465,\n",
       "   19077,\n",
       "   2522,\n",
       "   28228,\n",
       "   13186,\n",
       "   3334,\n",
       "   17086,\n",
       "   2024,\n",
       "   2109,\n",
       "   1999,\n",
       "   1996,\n",
       "   3949,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  3.0,\n",
       "  23],\n",
       " [[2029,\n",
       "   20992,\n",
       "   1999,\n",
       "   1996,\n",
       "   4319,\n",
       "   2465,\n",
       "   19077,\n",
       "   2522,\n",
       "   28228,\n",
       "   13186,\n",
       "   3334,\n",
       "   17086,\n",
       "   1998,\n",
       "   3424,\n",
       "   24158,\n",
       "   15464,\n",
       "   3170,\n",
       "   14930,\n",
       "   2024,\n",
       "   2109,\n",
       "   1999,\n",
       "   1996,\n",
       "   3949,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  2.0,\n",
       "  29],\n",
       " [[2029,\n",
       "   20992,\n",
       "   1999,\n",
       "   1996,\n",
       "   4319,\n",
       "   2465,\n",
       "   3424,\n",
       "   24158,\n",
       "   15464,\n",
       "   10586,\n",
       "   1010,\n",
       "   26721,\n",
       "   11649,\n",
       "   2389,\n",
       "   2024,\n",
       "   2109,\n",
       "   1999,\n",
       "   1996,\n",
       "   3949,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  2.0,\n",
       "  25],\n",
       " [[2029,\n",
       "   20992,\n",
       "   1999,\n",
       "   1996,\n",
       "   4319,\n",
       "   2465,\n",
       "   15429,\n",
       "   3526,\n",
       "   27790,\n",
       "   2869,\n",
       "   2024,\n",
       "   2109,\n",
       "   1999,\n",
       "   1996,\n",
       "   3949,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  3.0,\n",
       "  21],\n",
       " [[2029,\n",
       "   20992,\n",
       "   1999,\n",
       "   1996,\n",
       "   4319,\n",
       "   2465,\n",
       "   26721,\n",
       "   11649,\n",
       "   2389,\n",
       "   3424,\n",
       "   9905,\n",
       "   20660,\n",
       "   12863,\n",
       "   6074,\n",
       "   2024,\n",
       "   2109,\n",
       "   1999,\n",
       "   1996,\n",
       "   3949,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  2.0,\n",
       "  25],\n",
       " [[2029,\n",
       "   20992,\n",
       "   1999,\n",
       "   1996,\n",
       "   4319,\n",
       "   2465,\n",
       "   2035,\n",
       "   2121,\n",
       "   6914,\n",
       "   10047,\n",
       "   23041,\n",
       "   14573,\n",
       "   6906,\n",
       "   7685,\n",
       "   2024,\n",
       "   2109,\n",
       "   1999,\n",
       "   1996,\n",
       "   3949,\n",
       "   1997,\n",
       "   27395,\n",
       "   1054,\n",
       "   20535,\n",
       "   7315,\n",
       "   1029],\n",
       "  3.0,\n",
       "  25]]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_with_len "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_with_len.sort(key=lambda x: x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_queries_labels = [(query_lab[0], query_lab[1]) for query_lab in queries_with_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sorted_queries_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting into a dataset that can be used by tensorflow\n",
    "processed_dataset = tf.data.Dataset.from_generator(lambda: sorted_queries_labels, output_types=(tf.int32, tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 20\n",
    "batched_dataset = processed_dataset.padded_batch(BATCH_SIZE, padded_shapes=((None, ), ()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(20, 12), dtype=int32, numpy=\n",
       " array([[ 2054,  2003, 27395,  1054, 20535,  7315,  1029,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [ 2129,  2003, 27395,  1054, 20535,  7315,  6219,  1029,     0,\n",
       "             0,     0,     0],\n",
       "        [ 2054,  5320, 24590, 27395,  1054, 20535,  7315,  1029,     0,\n",
       "             0,     0,     0],\n",
       "        [ 2054,  2003, 16928, 27395,  1054, 20535,  7315,  1029,     0,\n",
       "             0,     0,     0],\n",
       "        [ 2054,  2024,  8030,  1997, 27395,  1054, 20535,  7315,  1029,\n",
       "             0,     0,     0],\n",
       "        [ 2054,  2024, 12763,  1997, 27395,  1054, 20535,  7315,  1029,\n",
       "             0,     0,     0],\n",
       "        [ 2054,  2024,  1996, 12763,  1997, 27395,  1054, 20535,  7315,\n",
       "          1029,     0,     0],\n",
       "        [ 2054,  2024, 22575,  3896,  1997, 27395,  1054, 20535,  7315,\n",
       "          1029,     0,     0],\n",
       "        [ 2029, 19077, 11360,  9556,  6592, 27395,  1054, 20535,  7315,\n",
       "          1029,     0,     0],\n",
       "        [ 2054,  2024,  1996,  5320,  1997, 27395,  1054, 20535,  7315,\n",
       "          1029,     0,     0],\n",
       "        [ 2054,  2024,  1996, 19077,  8030,  1997, 27395,  1054, 20535,\n",
       "          7315,  1029,     0],\n",
       "        [ 2054,  2003,  1996,  3171, 10859,  1997, 27395,  1054, 20535,\n",
       "          7315,  1029,     0],\n",
       "        [ 2054,  2003,  1996,  3795, 20272,  1997, 27395,  1054, 20535,\n",
       "          7315,  1029,     0],\n",
       "        [ 2054,  2024,  2825,  9495,  5876,  2005, 27395,  1054, 20535,\n",
       "          7315,  1029,     0],\n",
       "        [ 2054,  2003,  1996,  3426,  1997, 12348, 27395,  1054, 20535,\n",
       "          7315,  1029,     0],\n",
       "        [ 2054,  2003,  1996,  3426,  1997, 14638, 27395,  1054, 20535,\n",
       "          7315,  1029,     0],\n",
       "        [ 2054,  2024,  1996,  3949,  7047,  2005, 27395,  1054, 20535,\n",
       "          7315,  1029,     0],\n",
       "        [ 2043,  2003, 11707,  2729,  2005, 27395,  1054, 20535,  7315,\n",
       "          5393,  1029,     0],\n",
       "        [ 2054,  2024,  1996,  5751,  1998,  8030,  1997, 27395,  1054,\n",
       "         20535,  7315,  1029],\n",
       "        [ 2054,  2024,  1996,  2350,  3949,  9942,  2005, 27395,  1054,\n",
       "         20535,  7315,  1029]])>,\n",
       " <tf.Tensor: shape=(20,), dtype=int32, numpy=array([2, 3, 2, 2, 1, 3, 3, 2, 3, 1, 2, 1, 1, 1, 1, 1, 3, 2, 1, 1])>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(batched_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "TOTAL_BATCHES = math.ceil(len(sorted_queries_labels) / BATCH_SIZE)\n",
    "TEST_BATCHES = TOTAL_BATCHES // 10\n",
    "batched_dataset.shuffle(TOTAL_BATCHES)\n",
    "test_data = batched_dataset.take(TEST_BATCHES)\n",
    "train_data = batched_dataset.skip(TEST_BATCHES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TEXT_MODEL(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 vocabulary_size,\n",
    "                 embedding_dimensions=128,\n",
    "                 cnn_filters=50,\n",
    "                 dnn_units=512,\n",
    "                 model_output_classes=3,\n",
    "                 dropout_rate=0.1,\n",
    "                 training=False,\n",
    "                 name=\"text_model\"):\n",
    "        super(TEXT_MODEL, self).__init__(name=name)\n",
    "        \n",
    "        self.embedding = layers.Embedding(vocabulary_size,\n",
    "                                          embedding_dimensions)\n",
    "        self.cnn_layer1 = layers.Conv1D(filters=cnn_filters,\n",
    "                                        kernel_size=2,\n",
    "                                        padding=\"valid\",\n",
    "                                        activation=\"relu\")\n",
    "        self.cnn_layer2 = layers.Conv1D(filters=cnn_filters,\n",
    "                                        kernel_size=3,\n",
    "                                        padding=\"valid\",\n",
    "                                        activation=\"relu\")\n",
    "        self.cnn_layer3 = layers.Conv1D(filters=cnn_filters,\n",
    "                                        kernel_size=4,\n",
    "                                        padding=\"valid\",\n",
    "                                        activation=\"relu\")\n",
    "        self.pool = layers.GlobalMaxPool1D()\n",
    "        \n",
    "        self.dense_1 = layers.Dense(units=dnn_units, activation=\"relu\")\n",
    "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
    "        if model_output_classes == 2:\n",
    "            self.last_dense = layers.Dense(units=1,\n",
    "                                           activation=\"sigmoid\")\n",
    "        else:\n",
    "            self.last_dense = layers.Dense(units=model_output_classes,\n",
    "                                           activation=\"softmax\")\n",
    "    \n",
    "    def call(self, inputs, training):\n",
    "        l = self.embedding(inputs)\n",
    "        l_1 = self.cnn_layer1(l) \n",
    "        l_1 = self.pool(l_1) \n",
    "        l_2 = self.cnn_layer2(l) \n",
    "        l_2 = self.pool(l_2)\n",
    "        l_3 = self.cnn_layer3(l)\n",
    "        l_3 = self.pool(l_3) \n",
    "        \n",
    "        concatenated = tf.concat([l_1, l_2, l_3], axis=-1) # (batch_size, 3 * cnn_filters)\n",
    "        concatenated = self.dense_1(concatenated)\n",
    "        concatenated = self.dropout(concatenated, training)\n",
    "        model_output = self.last_dense(concatenated)\n",
    "        \n",
    "        return model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_LENGTH = len(tokenizer.vocab)\n",
    "EMB_DIM = 200\n",
    "CNN_FILTERS = 100\n",
    "DNN_UNITS = 256\n",
    "OUTPUT_CLASSES = 4\n",
    "\n",
    "DROPOUT_RATE = 0.2\n",
    "\n",
    "NB_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_model = TEXT_MODEL(vocabulary_size=VOCAB_LENGTH,\n",
    "                        embedding_dimensions=EMB_DIM,\n",
    "                        cnn_filters=CNN_FILTERS,\n",
    "                        dnn_units=DNN_UNITS,\n",
    "                        model_output_classes=OUTPUT_CLASSES,\n",
    "                        dropout_rate=DROPOUT_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "if OUTPUT_CLASSES == 2:\n",
    "    text_model.compile(loss=\"categorical_crossentropy\",\n",
    "                       optimizer=\"adam\",\n",
    "                       metrics=[\"accuracy\"])\n",
    "else:\n",
    "    text_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                       optimizer=\"adam\",\n",
    "                       metrics=[\"sparse_categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "6/6 [==============================] 1.3947 - sparse_categorical_accuracy: 0.350 - 0s 48ms/step - loss: 1.3507 - sparse_categorical_accuracy: 0.425 - 0s 65ms/step - loss: 1.3425 - sparse_categorical_accuracy: 0.350 - 0s 75ms/step - loss: 1.3471 - sparse_categorical_accuracy: 0.312 - 0s 79ms/step - loss: 1.3432 - sparse_categorical_accuracy: 0.290 - 1s 84ms/step - loss: 1.3405 - sparse_categorical_accuracy: 0.276 - 1s 96ms/step - loss: 1.3405 - sparse_categorical_accuracy: 0.2768\n",
      "Epoch 2/5\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.1622 - sparse_categorical_accuracy: 0.350 - ETA: 0s - loss: 1.1535 - sparse_categorical_accuracy: 0.325 - ETA: 0s - loss: 1.1324 - sparse_categorical_accuracy: 0.383 - ETA: 0s - loss: 1.1221 - sparse_categorical_accuracy: 0.387 - ETA: 0s - loss: 1.1104 - sparse_categorical_accuracy: 0.410 - ETA: 0s - loss: 1.0957 - sparse_categorical_accuracy: 0.419 - 1s 87ms/step - loss: 1.0957 - sparse_categorical_accuracy: 0.4196\n",
      "Epoch 3/5\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.1755 - sparse_categorical_accuracy: 0.350 - ETA: 0s - loss: 1.1799 - sparse_categorical_accuracy: 0.400 - ETA: 0s - loss: 1.1300 - sparse_categorical_accuracy: 0.416 - ETA: 0s - loss: 1.1031 - sparse_categorical_accuracy: 0.450 - ETA: 0s - loss: 1.0796 - sparse_categorical_accuracy: 0.460 - ETA: 0s - loss: 1.0472 - sparse_categorical_accuracy: 0.517 - 1s 86ms/step - loss: 1.0472 - sparse_categorical_accuracy: 0.5179\n",
      "Epoch 4/5\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.1763 - sparse_categorical_accuracy: 0.400 - ETA: 0s - loss: 1.1439 - sparse_categorical_accuracy: 0.425 - ETA: 0s - loss: 1.0876 - sparse_categorical_accuracy: 0.450 - ETA: 0s - loss: 1.0483 - sparse_categorical_accuracy: 0.500 - ETA: 0s - loss: 1.0320 - sparse_categorical_accuracy: 0.530 - ETA: 0s - loss: 1.0028 - sparse_categorical_accuracy: 0.571 - 0s 82ms/step - loss: 1.0028 - sparse_categorical_accuracy: 0.5714\n",
      "Epoch 5/5\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.0551 - sparse_categorical_accuracy: 0.450 - ETA: 0s - loss: 1.0206 - sparse_categorical_accuracy: 0.500 - ETA: 0s - loss: 0.9813 - sparse_categorical_accuracy: 0.566 - ETA: 0s - loss: 0.9516 - sparse_categorical_accuracy: 0.625 - ETA: 0s - loss: 0.9508 - sparse_categorical_accuracy: 0.620 - ETA: 0s - loss: 0.9293 - sparse_categorical_accuracy: 0.651 - 1s 85ms/step - loss: 0.9293 - sparse_categorical_accuracy: 0.6518\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16e1863cf48>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_model.fit(train_data, epochs=NB_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = text_model.evaluate(test_data)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
